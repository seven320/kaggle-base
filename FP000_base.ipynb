{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FP000-base",
      "provenance": [],
      "authorship_tag": "ABX9TyMqglWFFQygHLp63T7X5HMd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/seven320/kaggle-base/blob/main/FP000_base.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8OhibwrnFAQk",
        "outputId": "4158140a-76b7-4590-984b-c019d71654af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Mar 27 10:49:44 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   43C    P0    29W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, sys\n",
        "COLAB = \"google.colab\" in sys.modules\n",
        "\n",
        "if COLAB:\n",
        "    from google.colab import drive\n",
        "    from google.colab import output\n",
        "    drive.mount(\"/content/drive\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b09jV65gFc3Y",
        "outputId": "1d0126c6-3153-497d-b085-65c0fc41c2a7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# NOTEBOOK_NAME = y\n",
        "\n"
      ],
      "metadata": {
        "id": "9ltuVQ6b_grh"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if COLAB:\n",
        "    !pip install transformers > /dev/null\n",
        "    !pip install einops > /dev/null\n",
        "    !pip install timm > /dev/null\n",
        "    !pip install kaggle > /dev/null\n",
        "    !pip install kaggle_datasets > /dev/null\n",
        "    !pip install git+https://github.com/albumentations-team/albumentations\n",
        "    !pip install tensorflow-determinism\n",
        "    !pip install -q iterative-stratification\n",
        "    output.clear()"
      ],
      "metadata": {
        "id": "MvUvD3E2I6sj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "import json\n",
        "import math\n",
        "import os\n",
        "import random\n",
        "import re\n",
        "import time\n",
        "import copy\n",
        "import warnings\n",
        "from contextlib import contextmanager\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from pathlib import Path\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import GroupKFold, train_test_split, KFold\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "# import cv2\n",
        "# from torch.cuda.amp import autocast, GradScaler\n",
        "# from einops import rearrange as Rearrange\n",
        "from einops.layers.torch import Rearrange, Reduce\n",
        "import timm\n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "from transformers import AdamW, get_cosine_schedule_with_warmup\n",
        "from typing import Optional, Tuple\n",
        "from xgboost import XGBRegressor"
      ],
      "metadata": {
        "id": "VX7ZxFBMH3mX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "warnings.simplefilter('ignore')"
      ],
      "metadata": {
        "id": "3TLiFn8H_V90"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "jAG9b0Tb_YdF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "COMPE_NAME = \"\"\n",
        "BASE_DIR = f\"/content/drive/MyDrive/kaggle/{COMPE_NAME}\"\n",
        "\n",
        "# KAGGLE ONLY HAS 1, BUT OFFLINE, YOU CAN USE MORE\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\" #0,1,2,3 for four gpu"
      ],
      "metadata": {
        "id": "BiWCgj_XI4y2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if COLAB:\n",
        "    INPUT_DIR = Path(os.path.join(BASE_DIR ,f\"input\"))\n",
        "    INPUT_DIR.mkdir(exist_ok=True, parents=True)\n",
        "\n",
        "    SAVE_DIR = Path(os.path.join(BASE_DIR ,f\"models/{NOTEBOOK_NAME}\"))\n",
        "    SAVE_DIR.mkdir(exist_ok=True, parents=True)\n",
        "\n",
        "    OOF_DIR = Path(os.path.join(BASE_DIR, f\"oof/{NOTEBOOK_NAME}\"))\n",
        "    OOF_DIR.mkdir(exist_ok=True, parents = True)\n",
        "\n",
        "    SUB_DIR = Path(os.path.join(BASE_DIR, f\"submission/{NOTEBOOK_NAME}\"))\n",
        "    SUB_DIR.mkdir(exist_ok=True, parents = True)\n",
        "\n",
        "else:\n",
        "    INPUT_DIR = \"../input/feedback-prize-2021/train.csv\""
      ],
      "metadata": {
        "id": "tUAtLXzhI-Xr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv(os.path.join(INPUT_DIR, \"train.csv\"))\n",
        "test_df = pd.read_csv(os.path.join(INPUT_DIR, \"test.csv\"))\n",
        "sample_df = pd.read_csv(os.path.join(INPUT_DIR, \"sample_submission.csv\"))"
      ],
      "metadata": {
        "id": "z50ynnGpI-a-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#############\n",
        "## Utility ##\n",
        "#############\n",
        "@contextmanager\n",
        "def timer(name: str):\n",
        "    t0 = time.time()\n",
        "    print(f\"[{name}] start\")\n",
        "    yield\n",
        "    print(f\"[{name}] done - elapsed {time.time() - t0:.2f}s\")"
      ],
      "metadata": {
        "id": "QO13XyUmI-dG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Config:\n",
        "    COMPUTE_VAL = True\n",
        "    DEBUG = False\n",
        "\n",
        "    N_FOLD = 5\n",
        "    TRAIN_FOLD = [0]\n",
        "    SEED = 1234\n",
        "\n",
        "    IMG_SIZE = 224\n",
        "    \n",
        "    EXP_NAME = NOTEBOOK_NAME\n",
        "    N_EPOCHS = 100\n",
        "    BS = 64\n",
        "    LR = 1e-5  * BS\n",
        "    WEIGHT_DECAY = 1e-3\n",
        "\n",
        "    DEVICE = 'cuda'\n",
        "\n",
        "    MODEL_NAME = 'efficientnet_b0'\n",
        "    # FC_DIM = 512\n",
        "    SCHEDULER_PARAMS = {\n",
        "            \"lr_start\": 1e-5,\n",
        "            \"lr_max\": 1e-5 * 32,\n",
        "            \"lr_min\": 1e-6,\n",
        "            \"lr_ramp_ep\": 5,\n",
        "            \"lr_sus_ep\": 0,\n",
        "            \"lr_decay\": 0.8,\n",
        "        }\n",
        "\n",
        "device = torch.device(Config.DEVICE)"
      ],
      "metadata": {
        "id": "xSloYiF9I-fS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def seed_everything(seed):\n",
        "    \"\"\"\n",
        "    Seeds basic parameters for reproductibility of results\n",
        "    \n",
        "    Arguments:\n",
        "        seed {int} -- Number of the seed\n",
        "    \"\"\"\n",
        "    random.seed(seed)\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "def set_seed(seed = Config.SEED):\n",
        "    random.seed(seed)\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "seed_everything(42)"
      ],
      "metadata": {
        "id": "AEXTWNQFJNsz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_image(data_id, gray=False):\n",
        "    file_path = data_id\n",
        "    if gray:\n",
        "        img = cv2.cvtColor(cv2.imread(file_path), cv2.COLOR_BGR2GRAY)\n",
        "    else:\n",
        "        img = cv2.cvtColor(cv2.imread(file_path), cv2.COLOR_BGR2RGB)\n",
        "    return img"
      ],
      "metadata": {
        "id": "IeHnNhCrJNvb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "1JcbNGglJNxv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "wDNECR2JJN0N"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}